---
title: "Data analysis"
output: 
  html_notebook
---


# Hypotheses

We wish to test hypotheses relating to how routine activities of school
students influence crime in surrounding areas. Specifically, if school students'
activities cause increases in crime, we would expect:

  * H1: high schools to be associated with more crime on school weekdays but not 
    on vacation weekdays,
  * H2: high schools to be associated with more crime during the daytime but not 
    at night,
  * H3: high schools to be associated with more crime on streets and against 
    some types of business but not more crimes in dwellings,


# Read data

The data are already in the required format because data cleaning has been done,
so they can just be read directly from the RDS file.

```{r}
data <- read_rds("../analysis_data/blockgroup_data.Rds") %>% 
	select(-state, -county, -census_tract, -census_block_group) %>% 
	glimpse()
```


# Check data

We can check in detail that the data meets our expectations. This is done in 
this file rather than the data cleaning file in case any problems have been
introduced while saving and loading the data as a CSV.

```{r}
data %>% 
	
	# characters
	assert(is.character, geoid) %>% 
	assert(not_na, geoid) %>% 
	print_comment("👍 geoid is a character with no NA values") %>% 

	# characters with specific values
	assert(is.character, city_name) %>% 
	assert(in_set(cities$name), city_name) %>% 
	assert(not_na, city_name) %>% 
	print_comment("👍 city_name is a character, all values are valid CODE cities",
								"with no NA values") %>% 
	assert(is.character, public_location) %>% 
	assert(in_set("public", "private", "other"), public_location) %>% 
	assert(not_na, public_location) %>%
	print_comment("👍 public_location is a character, all values are valid with",
								"no NA values") %>% 
	assert(is.character, period) %>% 
	assert(in_set("non-school day, school time", "school day, non-school time", 
								"non-school day, non-school time", "school day, school time"), 
				 period) %>% 
	assert(not_na, period) %>% 
	print_comment("👍 period is a character, all values are valid with no NA", 
								"values") %>% 

	# positive integers
	assert(is.integer, count, school_count, school_students, pop_total) %>% 
	assert(within_bounds(0, Inf), count, school_count, school_students, 
				 pop_total) %>% 
	assert(not_na, count, school_count, school_students, pop_total) %>% 
	print_comment("👍 count, school_count, school-stude_ts and pop_total are",
								"positive integers with no NA values") %>% 

	# doubles
	assert(is.double, index_disadvantage, index_mobility, index_ethnic, 
				 perc_teen_sc) %>% 
	assert(not_na, index_disadvantage, index_mobility, index_ethnic, 
				 perc_teen_sc) %>% 
	print_comment("👍 index_disadvantage, index_mobility, index_ethnic and",
								"perc_teen_sc are doubles with no NA values") %>% 

	# doubles between zero and one
	assert(is.double, prop_overlap, prop_developed, land_cover_prop_22, 
				 land_cover_prop_23, land_cover_prop_24) %>% 
	assert(within_bounds(0, 1), prop_overlap, prop_developed, land_cover_prop_22, 
				 land_cover_prop_23, land_cover_prop_24) %>% 
	print_comment("👍 prop_overlap, prop_developed, land_cover_prop_22,",
								"land_cover_prop_23 and land_cover_prop_24 are doubles between",
								"0 and 1 with no NA values") %>% 

	# positive doubles
	assert(is.double, area_land, area_water, count_lag) %>% 
	assert(within_bounds(0, Inf), area_land, area_water, count_lag) %>% 
	assert(not_na, area_land, area_water, count_lag) %>% 
	print_comment("👍 area_land, area_water, pop_density and count_lag are",
								"positive doubles with no NA values") %>% 

	# factors
	assert(is.factor, crime_type) %>% 
	assert(not_na, crime_type) %>%
	print_comment("👍 crime_type is a factor with no NA values") %>% 

	# logicals
	assert(is.logical, school_day, school_time, school) %>% 
	# assert(not_na, school_day, school_time, school) %>% 
	print_comment("👍 school_day, school_time and school are logical with no NA",
								"values") %>% 

	glimpse()
```


# Select a model type

Since the dependent variable is a count of crimes, we expect the data to have an
overdispersed Poisson (i.e. negative binomial) distribution. This can be checked
visually and by calculating the ratio of the variance of the dependent variable
to the mean.

```{r}
data %>% 
	mutate(label = str_replace_all(period, ", ", "\n")) %>% 
	ggplot() + geom_histogram(aes(count), bins = 100) + 
	facet_grid(cols = vars(crime_type), rows = vars(label)) + 
	theme_minimal() +
	theme(strip.text.y = element_text(angle = 0))
```

The histograms suggest a Poisson-distributed response variable. We can check
the var/mean ratio to see if it is over-dispersed.

```{r}
data %>% 
	group_by(crime_type) %>% 
	summarise(cov = var(count) / mean(count))
```

We can see the variance is much greater than the mean, so (as expected) the 
response variable is overdispersed. Thus a NB model approach looks reasonable, 
subject to tests of the resulting models.

The histograms suggest some outlier blockgroups. We can identify these:

```{r}
data %>% 
	filter(count > 300)
```



# Descriptive analysis

## Schools

```{r}
data %>% 
	group_by(city_name, school) %>% 
	summarise(n = n()) %>% 
	spread(school, n) %>% 
	mutate(prop_with_schools = round(`TRUE` / (`TRUE` + `FALSE`), digits = 3))
```


# Test assumptions

In the models we control for disadvantage, population turnover, ethnic 
heterogeneity and the proportion of the population who are teenagers. To see if 
this is necessary, we can test whether places with schools are different in 
these respects to places without schools.

```{r}
map_df(
	c("index_disadvantage", "index_mobility", "index_ethnic", "perc_teen_sc", 
		"prop_developed"), 
	function (x) {
		wilcox.test(as.formula(paste(x, "~ school")), data = data) %>% 
			tidy() %>% 
			mutate(test = paste("Wilcoxcon: ", x, "~ school"))
	}) %>%
	select(test, statistic, p.value, alternative) %>% 
	mutate(p.value = round(p.value, digits = 3))
```

All these variables are associated with the response variable. For this reason 
we will include them in the model for now.


# Build models

We will store all the models in a single list containing a list for each type of
crime. We can also initiate a list for formulae.

```{r}
f <- list()

m <- list(
	"aslt" = list(),
	"robb" = list()
)
```

## Create data for testing H1 and H2

We can test H1 and H2 together, because data to test them are available in all
cities. The data for this model require collapsing of rows so that there are not
separate rows for offenses in public/private places.

```{r}
data_h1 <- data %>% 
	group_by(geoid, crime_type, period) %>% 
	summarise(
		count = sum(count),
		count_lag = sum(count_lag),
		city_name = first(city_name),
		school = first(school),
		school_count = first(school_count),
		school_students = first(school_students),
		pop_total = first(pop_total),
		pop_total_sc = first(pop_total_sc),
		index_disadvantage = first(index_disadvantage),
		index_mobility = first(index_mobility),
		index_ethnic = first(index_ethnic),
		perc_teen_sc = first(perc_teen_sc),
		prop_developed = first(prop_developed)
	) %>% 
	# we must ungroup() before mutate() otherwise dplyr will mutate by group
	ungroup() %>% 
	# the count_lag variable must be scaled or the model is unlikely to converge,
	# but this must be done after count_lag is summed
	# first() within summarise() appears to convert factors to character, but
	# grouping variables must be factors, so city_name and period must be 
	# converted back to factors
	mutate(
		count_lag_sc = as.numeric(scale(count_lag, center = TRUE, scale = TRUE)),
		city_name = as.factor(city_name), 
		period = as.factor(period)
	) %>% 
	glimpse()
```


## Testing H1 and H2

The unit of analysis is the census block group. There are four records for each
block group for each crime type, one for each combination of school day and 
school time. The data are therefore clustered in two (non-nested) ways, by city 
and by period. The model must also control for socio-economic variables and for 
spatial autocorrelation.

```{r}
f$h1 <- count ~ count_lag_sc + (pop_total_sc + index_disadvantage + 
	index_mobility + index_ethnic + perc_teen_sc + school | period) +
	(school | city_name)

system.time(
	m$aslt$h1 <- glmer.nb(
		f$h1, 
		data = subset(data_h1, crime_type == "assault" & 
										city_name != "Fort Worth"),
		control = glmerControl(optCtrl = list(maxfun = 10^7), calc.derivs = FALSE)
	)
)

write_rds(m, "../analysis_data/models.Rds")
```

## Post-hoc tests

Tests for independence of residuals etc

Consider Legrange Multiplier test for residual spatial autocorrelation


